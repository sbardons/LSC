{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbbf5a53-bb8c-4840-8316-775992b09ae5",
   "metadata": {},
   "source": [
    "## Task 2 Week 5\n",
    "\n",
    "### Classify the CIFAR-10 dataset using Keras deep net, **sequential approach** and **functional API** approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90ab579f-cfdb-47a8-a214-c3b165c25f35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53f5f6cb-a20a-45e2-92d5-6266e117aabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "labels=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc342e0-1c0b-4de5-8684-2bb7fec38bff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train samples = (50000, 32, 32, 3)\n",
      "y_train samples = (50000, 1)\n",
      "x_test samples = (10000, 32, 32, 3)\n",
      "y_test samples = (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('x_train samples = ' + str(x_train.shape)) #each image is stored as numpy array 28x28\n",
    "print ('y_train samples = ' + str(y_train.shape)) #labels\n",
    "\n",
    "print ('x_test samples = ' + str(x_test.shape))\n",
    "print ('y_test samples = ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "354099ae-5959-46ae-817b-8cf1943684e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_input samples = (50000, 3072)\n",
      "y_input samples = (50000, 10)\n",
      "y_input samples = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# preprocess: normalise and re-shape\n",
    "y_input = tf.keras.utils.to_categorical(y_train)      #one hot encoder\n",
    "# this line was reshaping to 784 for MNIST as we had 28x28 greyscale images, now it's 32x32x3=3072\n",
    "# pixel range from 0 to 255 So dividing all the values by 255 will convert it to range from 0 to 1\n",
    "x_input = (np.reshape(x_train, (x_train.shape[0], 3072)) / 255.0).astype(np.float32)\n",
    "\n",
    "print ('x_input samples = ' + str(x_input.shape))\n",
    "print ('y_input samples = ' + str(y_input.shape))\n",
    "\n",
    "print ('y_input samples = ' + str(y_input))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05e4d012-20ed-4b21-b814-7a4c75bb4b6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_valid = tf.keras.utils.to_categorical(y_test)\n",
    "x_valid = np.reshape(x_test, (x_test.shape[0], 3072)) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e10e7775-5a53-47c9-bdbe-726b2f9dffe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_valid shape = (50000, 3072)\n",
      "x_valid shape = [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print ('y_valid shape = ' + str(x_input.shape))\n",
    "print ('x_valid shape = ' + str(y_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65615027-41c0-4812-9978-ab31c9132490",
   "metadata": {},
   "source": [
    "## Sequential Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4099c6a-e091-49c5-af09-02108fbcaf23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 14:26:52.959370: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 14:26:53.475253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 198 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n",
      "2023-07-07 14:26:53.489378: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 198.44M (208076800 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 512 units to the model:\n",
    "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c14073-24fa-48d5-abfa-af4b2dc739f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next, we need to compile the model (this sets the optimizer and the loss function), and then we can train the model.\n",
    "We set the validation data to be our test dataset so that we can observe the accuracy on the test data during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8553c7af-1a87-4873-93ea-4b3fb4339f9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 2.0928 - accuracy: 0.2959 - val_loss: 1.9029 - val_accuracy: 0.3241\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.7897 - accuracy: 0.3677 - val_loss: 1.7571 - val_accuracy: 0.3806\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.7163 - accuracy: 0.3958 - val_loss: 1.6953 - val_accuracy: 0.3981\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.6695 - accuracy: 0.4114 - val_loss: 1.6402 - val_accuracy: 0.4182\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.6240 - accuracy: 0.4264 - val_loss: 1.6185 - val_accuracy: 0.4281\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.5797 - accuracy: 0.4424 - val_loss: 1.5842 - val_accuracy: 0.4319\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.5522 - accuracy: 0.4528 - val_loss: 1.5722 - val_accuracy: 0.4413\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.5274 - accuracy: 0.4610 - val_loss: 1.5811 - val_accuracy: 0.4353\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.5071 - accuracy: 0.4699 - val_loss: 1.5257 - val_accuracy: 0.4589\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4873 - accuracy: 0.4755 - val_loss: 1.5133 - val_accuracy: 0.4568\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4754 - accuracy: 0.4801 - val_loss: 1.5138 - val_accuracy: 0.4610\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4591 - accuracy: 0.4853 - val_loss: 1.5066 - val_accuracy: 0.4640\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4450 - accuracy: 0.4899 - val_loss: 1.5041 - val_accuracy: 0.4651\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4243 - accuracy: 0.4968 - val_loss: 1.4887 - val_accuracy: 0.4712\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4165 - accuracy: 0.5021 - val_loss: 1.5060 - val_accuracy: 0.4609\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.4063 - accuracy: 0.5039 - val_loss: 1.4902 - val_accuracy: 0.4656\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3980 - accuracy: 0.5088 - val_loss: 1.5364 - val_accuracy: 0.4635\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3851 - accuracy: 0.5120 - val_loss: 1.4970 - val_accuracy: 0.4751\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3835 - accuracy: 0.5107 - val_loss: 1.4577 - val_accuracy: 0.4831\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3689 - accuracy: 0.5178 - val_loss: 1.4693 - val_accuracy: 0.4798\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3590 - accuracy: 0.5198 - val_loss: 1.4827 - val_accuracy: 0.4773\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3496 - accuracy: 0.5252 - val_loss: 1.4774 - val_accuracy: 0.4811\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3361 - accuracy: 0.5279 - val_loss: 1.4773 - val_accuracy: 0.4753\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3356 - accuracy: 0.5301 - val_loss: 1.4515 - val_accuracy: 0.4890\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3269 - accuracy: 0.5312 - val_loss: 1.4414 - val_accuracy: 0.4932\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3238 - accuracy: 0.5310 - val_loss: 1.4427 - val_accuracy: 0.4879\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3172 - accuracy: 0.5362 - val_loss: 1.4657 - val_accuracy: 0.4854\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3069 - accuracy: 0.5404 - val_loss: 1.4199 - val_accuracy: 0.5036\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.3026 - accuracy: 0.5405 - val_loss: 1.4606 - val_accuracy: 0.4823\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2918 - accuracy: 0.5445 - val_loss: 1.4399 - val_accuracy: 0.4906\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2917 - accuracy: 0.5452 - val_loss: 1.4264 - val_accuracy: 0.5037\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2816 - accuracy: 0.5484 - val_loss: 1.4286 - val_accuracy: 0.4991\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2719 - accuracy: 0.5501 - val_loss: 1.4653 - val_accuracy: 0.4830\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2748 - accuracy: 0.5497 - val_loss: 1.4222 - val_accuracy: 0.4967\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2657 - accuracy: 0.5533 - val_loss: 1.4374 - val_accuracy: 0.4972\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2638 - accuracy: 0.5533 - val_loss: 1.4207 - val_accuracy: 0.4986\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2549 - accuracy: 0.5554 - val_loss: 1.4285 - val_accuracy: 0.4968\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2568 - accuracy: 0.5549 - val_loss: 1.4299 - val_accuracy: 0.5021\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2449 - accuracy: 0.5608 - val_loss: 1.4354 - val_accuracy: 0.4969\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2492 - accuracy: 0.5589 - val_loss: 1.4539 - val_accuracy: 0.4965\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2433 - accuracy: 0.5591 - val_loss: 1.4321 - val_accuracy: 0.4985\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2325 - accuracy: 0.5647 - val_loss: 1.4421 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2333 - accuracy: 0.5644 - val_loss: 1.4579 - val_accuracy: 0.4928\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2204 - accuracy: 0.5685 - val_loss: 1.4825 - val_accuracy: 0.4983\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2209 - accuracy: 0.5684 - val_loss: 1.4289 - val_accuracy: 0.5016\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2209 - accuracy: 0.5675 - val_loss: 1.4487 - val_accuracy: 0.4887\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2186 - accuracy: 0.5684 - val_loss: 1.4351 - val_accuracy: 0.5003\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2110 - accuracy: 0.5728 - val_loss: 1.4499 - val_accuracy: 0.4883\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2065 - accuracy: 0.5737 - val_loss: 1.4033 - val_accuracy: 0.5103\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2020 - accuracy: 0.5729 - val_loss: 1.4487 - val_accuracy: 0.4980\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.2021 - accuracy: 0.5728 - val_loss: 1.4090 - val_accuracy: 0.5132\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1947 - accuracy: 0.5771 - val_loss: 1.4315 - val_accuracy: 0.5088\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1937 - accuracy: 0.5765 - val_loss: 1.4307 - val_accuracy: 0.5011\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1895 - accuracy: 0.5796 - val_loss: 1.4459 - val_accuracy: 0.4985\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1813 - accuracy: 0.5816 - val_loss: 1.4530 - val_accuracy: 0.4922\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1822 - accuracy: 0.5817 - val_loss: 1.4282 - val_accuracy: 0.5063\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1860 - accuracy: 0.5808 - val_loss: 1.4607 - val_accuracy: 0.4927\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1923 - accuracy: 0.5781 - val_loss: 1.5291 - val_accuracy: 0.4743\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1869 - accuracy: 0.5810 - val_loss: 1.4186 - val_accuracy: 0.5101\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1671 - accuracy: 0.5894 - val_loss: 1.4688 - val_accuracy: 0.4998\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1690 - accuracy: 0.5859 - val_loss: 1.4455 - val_accuracy: 0.4919\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1709 - accuracy: 0.5854 - val_loss: 1.4600 - val_accuracy: 0.4940\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1614 - accuracy: 0.5867 - val_loss: 1.4316 - val_accuracy: 0.5043\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1663 - accuracy: 0.5876 - val_loss: 1.4591 - val_accuracy: 0.4921\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1538 - accuracy: 0.5929 - val_loss: 1.4664 - val_accuracy: 0.4984\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1684 - accuracy: 0.5862 - val_loss: 1.4498 - val_accuracy: 0.4993\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1566 - accuracy: 0.5901 - val_loss: 1.4309 - val_accuracy: 0.5079\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1474 - accuracy: 0.5937 - val_loss: 1.4482 - val_accuracy: 0.5029\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1475 - accuracy: 0.5932 - val_loss: 1.4459 - val_accuracy: 0.5003\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1472 - accuracy: 0.5949 - val_loss: 1.4350 - val_accuracy: 0.5053\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1423 - accuracy: 0.5965 - val_loss: 1.4863 - val_accuracy: 0.4903\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1466 - accuracy: 0.5940 - val_loss: 1.4328 - val_accuracy: 0.5044\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1335 - accuracy: 0.5975 - val_loss: 1.4373 - val_accuracy: 0.5052\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1289 - accuracy: 0.5996 - val_loss: 1.4608 - val_accuracy: 0.4999\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1325 - accuracy: 0.5978 - val_loss: 1.4479 - val_accuracy: 0.5076\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1242 - accuracy: 0.6025 - val_loss: 1.4749 - val_accuracy: 0.4983\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1239 - accuracy: 0.6028 - val_loss: 1.4874 - val_accuracy: 0.4953\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1306 - accuracy: 0.6005 - val_loss: 1.5430 - val_accuracy: 0.4790\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1266 - accuracy: 0.6011 - val_loss: 1.4648 - val_accuracy: 0.4959\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1199 - accuracy: 0.6022 - val_loss: 1.4569 - val_accuracy: 0.4956\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1212 - accuracy: 0.6042 - val_loss: 1.4466 - val_accuracy: 0.5009\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1168 - accuracy: 0.6024 - val_loss: 1.4642 - val_accuracy: 0.4968\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1162 - accuracy: 0.6037 - val_loss: 1.4556 - val_accuracy: 0.5025\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1158 - accuracy: 0.6046 - val_loss: 1.4854 - val_accuracy: 0.4940\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1132 - accuracy: 0.6057 - val_loss: 1.5126 - val_accuracy: 0.4896\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1121 - accuracy: 0.6061 - val_loss: 1.5020 - val_accuracy: 0.4894\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1085 - accuracy: 0.6056 - val_loss: 1.4584 - val_accuracy: 0.4991\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1026 - accuracy: 0.6084 - val_loss: 1.4499 - val_accuracy: 0.5049\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0963 - accuracy: 0.6130 - val_loss: 1.4848 - val_accuracy: 0.4996\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.1032 - accuracy: 0.6077 - val_loss: 1.4821 - val_accuracy: 0.4973\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0962 - accuracy: 0.6093 - val_loss: 1.4742 - val_accuracy: 0.5011\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0947 - accuracy: 0.6131 - val_loss: 1.4542 - val_accuracy: 0.5040\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0944 - accuracy: 0.6121 - val_loss: 1.4959 - val_accuracy: 0.4907\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0904 - accuracy: 0.6120 - val_loss: 1.4951 - val_accuracy: 0.5011\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0825 - accuracy: 0.6164 - val_loss: 1.5016 - val_accuracy: 0.4901\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0859 - accuracy: 0.6132 - val_loss: 1.5542 - val_accuracy: 0.4813\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0877 - accuracy: 0.6131 - val_loss: 1.5053 - val_accuracy: 0.4922\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0863 - accuracy: 0.6141 - val_loss: 1.4773 - val_accuracy: 0.5013\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0781 - accuracy: 0.6182 - val_loss: 1.4966 - val_accuracy: 0.4922\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 1s 3ms/step - loss: 1.0760 - accuracy: 0.6194 - val_loss: 1.5134 - val_accuracy: 0.4892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1f0f2adc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_input, y_input, epochs=100, batch_size=256,validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ebd2d-bd5e-4cde-873d-502722f882e5",
   "metadata": {},
   "source": [
    "## Functional API Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1572ed27-22ec-4ffc-b22c-0d1a9fb61fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create the input layer and combine with further dense layers,\n",
    "input_layer = tf.keras.Input(shape=(3072,))\n",
    "# Add a densely-connected layer with 512 units to the model:\n",
    "output_layer = tf.keras.layers.Dense(512, activation='relu')(input_layer)\n",
    "\n",
    "# Add a softmax layer with 10 output units:\n",
    "output_layer = tf.keras.layers.Dense(10, activation='softmax')(output_layer)\n",
    "\n",
    "#Note that when input data is one-dimensional, we have to define the shape wih a hanging last dimension (3072,) so\n",
    "#that it can accommodate an array of input data. Next we construct the model by specifying the inputs and outputs,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df453ec6-2f0e-45d5-94b8-6378c81cc585",
   "metadata": {
    "tags": []
   },
   "source": [
    "Next we construct the model by specifying the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0f18267-2314-4fdb-b74a-bcc3fbae698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 3072)]            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1573376   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,578,506\n",
      "Trainable params: 1,578,506\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Model(inputs=input_layer,outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3652cf80-fa33-44fa-acde-0e5c47760a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "196/196 [==============================] - 2s 6ms/step - loss: 2.0107 - accuracy: 0.3094 - val_loss: 1.7689 - val_accuracy: 0.3835\n",
      "Epoch 2/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.7451 - accuracy: 0.3856 - val_loss: 1.6968 - val_accuracy: 0.4119\n",
      "Epoch 3/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.6722 - accuracy: 0.4118 - val_loss: 1.6524 - val_accuracy: 0.4254\n",
      "Epoch 4/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.6219 - accuracy: 0.4259 - val_loss: 1.5934 - val_accuracy: 0.4420\n",
      "Epoch 5/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.5810 - accuracy: 0.4443 - val_loss: 1.5772 - val_accuracy: 0.4370\n",
      "Epoch 6/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.5554 - accuracy: 0.4538 - val_loss: 1.5782 - val_accuracy: 0.4415\n",
      "Epoch 7/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.5344 - accuracy: 0.4615 - val_loss: 1.5749 - val_accuracy: 0.4405\n",
      "Epoch 8/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.5078 - accuracy: 0.4702 - val_loss: 1.5491 - val_accuracy: 0.4487\n",
      "Epoch 9/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.4764 - accuracy: 0.4784 - val_loss: 1.5079 - val_accuracy: 0.4644\n",
      "Epoch 10/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.4692 - accuracy: 0.4808 - val_loss: 1.4843 - val_accuracy: 0.4723\n",
      "Epoch 11/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.4474 - accuracy: 0.4899 - val_loss: 1.4901 - val_accuracy: 0.4722\n",
      "Epoch 12/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.4302 - accuracy: 0.4976 - val_loss: 1.6298 - val_accuracy: 0.4287\n",
      "Epoch 13/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.4159 - accuracy: 0.5012 - val_loss: 1.4562 - val_accuracy: 0.4881\n",
      "Epoch 14/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3977 - accuracy: 0.5083 - val_loss: 1.4717 - val_accuracy: 0.4787\n",
      "Epoch 15/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3936 - accuracy: 0.5077 - val_loss: 1.4309 - val_accuracy: 0.4972\n",
      "Epoch 16/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3825 - accuracy: 0.5148 - val_loss: 1.4285 - val_accuracy: 0.4976\n",
      "Epoch 17/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3696 - accuracy: 0.5164 - val_loss: 1.4665 - val_accuracy: 0.4825\n",
      "Epoch 18/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3531 - accuracy: 0.5245 - val_loss: 1.4432 - val_accuracy: 0.4864\n",
      "Epoch 19/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3372 - accuracy: 0.5278 - val_loss: 1.5011 - val_accuracy: 0.4749\n",
      "Epoch 20/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3308 - accuracy: 0.5314 - val_loss: 1.4413 - val_accuracy: 0.4882\n",
      "Epoch 21/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3217 - accuracy: 0.5358 - val_loss: 1.4519 - val_accuracy: 0.4850\n",
      "Epoch 22/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3068 - accuracy: 0.5403 - val_loss: 1.4404 - val_accuracy: 0.4869\n",
      "Epoch 23/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.3005 - accuracy: 0.5424 - val_loss: 1.4206 - val_accuracy: 0.5038\n",
      "Epoch 24/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2881 - accuracy: 0.5446 - val_loss: 1.4291 - val_accuracy: 0.5003\n",
      "Epoch 25/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2812 - accuracy: 0.5495 - val_loss: 1.4132 - val_accuracy: 0.5064\n",
      "Epoch 26/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2706 - accuracy: 0.5527 - val_loss: 1.3890 - val_accuracy: 0.5132\n",
      "Epoch 27/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2678 - accuracy: 0.5538 - val_loss: 1.4364 - val_accuracy: 0.4942\n",
      "Epoch 28/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2560 - accuracy: 0.5585 - val_loss: 1.4167 - val_accuracy: 0.5004\n",
      "Epoch 29/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2486 - accuracy: 0.5588 - val_loss: 1.4368 - val_accuracy: 0.4980\n",
      "Epoch 30/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2428 - accuracy: 0.5616 - val_loss: 1.4110 - val_accuracy: 0.5013\n",
      "Epoch 31/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2350 - accuracy: 0.5650 - val_loss: 1.4432 - val_accuracy: 0.5008\n",
      "Epoch 32/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2276 - accuracy: 0.5659 - val_loss: 1.4151 - val_accuracy: 0.5053\n",
      "Epoch 33/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2199 - accuracy: 0.5668 - val_loss: 1.4023 - val_accuracy: 0.5078\n",
      "Epoch 34/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2214 - accuracy: 0.5720 - val_loss: 1.4731 - val_accuracy: 0.4844\n",
      "Epoch 35/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.2113 - accuracy: 0.5699 - val_loss: 1.3979 - val_accuracy: 0.5144\n",
      "Epoch 36/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1997 - accuracy: 0.5759 - val_loss: 1.3955 - val_accuracy: 0.5126\n",
      "Epoch 37/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1994 - accuracy: 0.5766 - val_loss: 1.4607 - val_accuracy: 0.4804\n",
      "Epoch 38/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1886 - accuracy: 0.5801 - val_loss: 1.4040 - val_accuracy: 0.5078\n",
      "Epoch 39/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1871 - accuracy: 0.5814 - val_loss: 1.3992 - val_accuracy: 0.5195\n",
      "Epoch 40/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1746 - accuracy: 0.5838 - val_loss: 1.4276 - val_accuracy: 0.5014\n",
      "Epoch 41/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1681 - accuracy: 0.5880 - val_loss: 1.4180 - val_accuracy: 0.5061\n",
      "Epoch 42/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1655 - accuracy: 0.5878 - val_loss: 1.4181 - val_accuracy: 0.5033\n",
      "Epoch 43/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1636 - accuracy: 0.5893 - val_loss: 1.4345 - val_accuracy: 0.5049\n",
      "Epoch 44/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1529 - accuracy: 0.5926 - val_loss: 1.4294 - val_accuracy: 0.5089\n",
      "Epoch 45/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1525 - accuracy: 0.5918 - val_loss: 1.4135 - val_accuracy: 0.5113\n",
      "Epoch 46/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1353 - accuracy: 0.5972 - val_loss: 1.4031 - val_accuracy: 0.5128\n",
      "Epoch 47/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1522 - accuracy: 0.5907 - val_loss: 1.4344 - val_accuracy: 0.5078\n",
      "Epoch 48/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1334 - accuracy: 0.5999 - val_loss: 1.4341 - val_accuracy: 0.5074\n",
      "Epoch 49/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1216 - accuracy: 0.6025 - val_loss: 1.4153 - val_accuracy: 0.5100\n",
      "Epoch 50/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1167 - accuracy: 0.6050 - val_loss: 1.4677 - val_accuracy: 0.4907\n",
      "Epoch 51/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1208 - accuracy: 0.6033 - val_loss: 1.4302 - val_accuracy: 0.5040\n",
      "Epoch 52/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1088 - accuracy: 0.6097 - val_loss: 1.4156 - val_accuracy: 0.5158\n",
      "Epoch 53/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1080 - accuracy: 0.6085 - val_loss: 1.4033 - val_accuracy: 0.5210\n",
      "Epoch 54/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.1061 - accuracy: 0.6071 - val_loss: 1.4469 - val_accuracy: 0.4989\n",
      "Epoch 55/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0984 - accuracy: 0.6134 - val_loss: 1.4243 - val_accuracy: 0.5121\n",
      "Epoch 56/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0957 - accuracy: 0.6119 - val_loss: 1.4250 - val_accuracy: 0.5055\n",
      "Epoch 57/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0959 - accuracy: 0.6101 - val_loss: 1.4238 - val_accuracy: 0.5086\n",
      "Epoch 58/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0890 - accuracy: 0.6151 - val_loss: 1.4465 - val_accuracy: 0.5084\n",
      "Epoch 59/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0793 - accuracy: 0.6184 - val_loss: 1.4730 - val_accuracy: 0.4978\n",
      "Epoch 60/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0766 - accuracy: 0.6191 - val_loss: 1.4175 - val_accuracy: 0.5156\n",
      "Epoch 61/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0717 - accuracy: 0.6212 - val_loss: 1.4682 - val_accuracy: 0.5032\n",
      "Epoch 62/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0665 - accuracy: 0.6224 - val_loss: 1.4753 - val_accuracy: 0.5033\n",
      "Epoch 63/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0682 - accuracy: 0.6214 - val_loss: 1.5016 - val_accuracy: 0.4950\n",
      "Epoch 64/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0605 - accuracy: 0.6254 - val_loss: 1.4667 - val_accuracy: 0.5079\n",
      "Epoch 65/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0583 - accuracy: 0.6256 - val_loss: 1.4620 - val_accuracy: 0.5004\n",
      "Epoch 66/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0535 - accuracy: 0.6272 - val_loss: 1.4648 - val_accuracy: 0.5057\n",
      "Epoch 67/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0435 - accuracy: 0.6307 - val_loss: 1.4654 - val_accuracy: 0.5049\n",
      "Epoch 68/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0429 - accuracy: 0.6299 - val_loss: 1.5277 - val_accuracy: 0.4876\n",
      "Epoch 69/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0445 - accuracy: 0.6300 - val_loss: 1.4414 - val_accuracy: 0.5111\n",
      "Epoch 70/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0362 - accuracy: 0.6344 - val_loss: 1.4688 - val_accuracy: 0.5045\n",
      "Epoch 71/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0455 - accuracy: 0.6294 - val_loss: 1.4799 - val_accuracy: 0.5067\n",
      "Epoch 72/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0271 - accuracy: 0.6358 - val_loss: 1.4596 - val_accuracy: 0.5105\n",
      "Epoch 73/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0293 - accuracy: 0.6337 - val_loss: 1.4553 - val_accuracy: 0.5029\n",
      "Epoch 74/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0233 - accuracy: 0.6365 - val_loss: 1.4799 - val_accuracy: 0.5077\n",
      "Epoch 75/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0208 - accuracy: 0.6354 - val_loss: 1.4556 - val_accuracy: 0.5108\n",
      "Epoch 76/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.6417 - val_loss: 1.4522 - val_accuracy: 0.5130\n",
      "Epoch 77/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0145 - accuracy: 0.6412 - val_loss: 1.5306 - val_accuracy: 0.5007\n",
      "Epoch 78/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0107 - accuracy: 0.6422 - val_loss: 1.5030 - val_accuracy: 0.4995\n",
      "Epoch 79/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9989 - accuracy: 0.6460 - val_loss: 1.4768 - val_accuracy: 0.5077\n",
      "Epoch 80/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0047 - accuracy: 0.6424 - val_loss: 1.4816 - val_accuracy: 0.5100\n",
      "Epoch 81/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9893 - accuracy: 0.6500 - val_loss: 1.4796 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 1.0016 - accuracy: 0.6471 - val_loss: 1.4992 - val_accuracy: 0.5044\n",
      "Epoch 83/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9910 - accuracy: 0.6488 - val_loss: 1.4706 - val_accuracy: 0.5104\n",
      "Epoch 84/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9809 - accuracy: 0.6520 - val_loss: 1.4895 - val_accuracy: 0.5038\n",
      "Epoch 85/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9821 - accuracy: 0.6512 - val_loss: 1.4946 - val_accuracy: 0.5048\n",
      "Epoch 86/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9939 - accuracy: 0.6459 - val_loss: 1.5122 - val_accuracy: 0.4986\n",
      "Epoch 87/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9768 - accuracy: 0.6542 - val_loss: 1.5219 - val_accuracy: 0.4979\n",
      "Epoch 88/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9752 - accuracy: 0.6545 - val_loss: 1.4903 - val_accuracy: 0.5051\n",
      "Epoch 89/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9715 - accuracy: 0.6539 - val_loss: 1.5105 - val_accuracy: 0.5027\n",
      "Epoch 90/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9790 - accuracy: 0.6527 - val_loss: 1.4789 - val_accuracy: 0.5161\n",
      "Epoch 91/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9646 - accuracy: 0.6566 - val_loss: 1.5197 - val_accuracy: 0.5028\n",
      "Epoch 92/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9665 - accuracy: 0.6581 - val_loss: 1.5381 - val_accuracy: 0.5075\n",
      "Epoch 93/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9557 - accuracy: 0.6617 - val_loss: 1.5111 - val_accuracy: 0.5020\n",
      "Epoch 94/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9598 - accuracy: 0.6578 - val_loss: 1.5513 - val_accuracy: 0.4958\n",
      "Epoch 95/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9595 - accuracy: 0.6620 - val_loss: 1.5481 - val_accuracy: 0.5033\n",
      "Epoch 96/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9463 - accuracy: 0.6645 - val_loss: 1.5460 - val_accuracy: 0.5006\n",
      "Epoch 97/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9513 - accuracy: 0.6620 - val_loss: 1.5506 - val_accuracy: 0.5039\n",
      "Epoch 98/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9408 - accuracy: 0.6652 - val_loss: 1.5467 - val_accuracy: 0.4955\n",
      "Epoch 99/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9510 - accuracy: 0.6637 - val_loss: 1.5128 - val_accuracy: 0.5063\n",
      "Epoch 100/100\n",
      "196/196 [==============================] - 1s 4ms/step - loss: 0.9336 - accuracy: 0.6670 - val_loss: 1.5213 - val_accuracy: 0.5106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c5c03d040>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#The compilation and training then proceeds as per the sequential model,\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_input, y_input, epochs=100, batch_size=256,validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a898f9-55d3-441a-a41e-cc7f1257776e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7cc4db-294a-4ee9-8eb2-321bdc6af9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
