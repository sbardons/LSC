{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2422b8-4d25-4850-a8af-08660e7fb69f",
   "metadata": {},
   "source": [
    "Cannot run on JupyterLab or Colab: use your own pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2c1dc8-8b85-4e6a-8fc3-01c1e6892dc8",
   "metadata": {},
   "source": [
    "# The following code will combine the VGG classifier with live input from a webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10939cd0-e43e-4f14-a240-6d18ee342190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa2e70-07cf-4507-b9d8-7a78bc68998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the VGG16 classifier This command will create the classifier and also download the pre-trained network\n",
    "# weights so that it is ready to be used.\n",
    "model = VGG16()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb00880c-6e4f-4d21-a1e4-c9f2d3967ec9",
   "metadata": {},
   "source": [
    "Take input from the webcam and classify whatâ€™s in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479774a-1b8f-4887-98d6-61e4e6b58d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we close any open windows (just to clean up)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# capture video from the webcamera\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# now we start an infinite loop that can be stopped by pressing esc\n",
    "while True:\n",
    "    # we read in an image from the camera\n",
    "    _ , img = cam.read()\n",
    "    # we resize the image so that it is 224x224 as required\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    # now we preprocess the image so that it is in the right format\n",
    "    cls_im = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)\n",
    "    cls_im = preprocess_input(cls_im)\n",
    "    # next make the prediction and decode the output\n",
    "    prediction = model.predict(cls_im[None,:])\n",
    "    label = decode_predictions(prediction,top=1)[0][0]\n",
    "    # if the certainty score is greater than 10% annotate the image\n",
    "    if label[2]>0.1:\n",
    "        cv2.putText(img,label[1],(10,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(200,0,0),2)\n",
    "    # finally display it to the screen\n",
    "    cv2.imshow('window',img)\n",
    "    # these lines check if a key has been pressed\n",
    "    k = cv2.waitKey(33)\n",
    "    if k == 27: # if the esc pressed k==27\n",
    "        break # so we'll exit the loop\n",
    "        \n",
    "# now we're done so we'll close the camera and close the windows\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
