{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b89e61e1-10cd-4424-9a4c-96e2316db032",
   "metadata": {},
   "source": [
    "## Page 25 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b0d57f-5c2d-4b24-814f-1220f0d315fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b12842-d788-42ab-8fec-c6703d4eff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"MyAppName\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba06b47e-d13d-4193-a089-5f8d8f8fd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11311a76-4a07-4658-bbc7-d58e833b2890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-08 18:25:54--  https://raw.githubusercontent.com/tidyverse/ggplot2/main/data-raw/diamonds.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2772143 (2.6M) [text/plain]\n",
      "Saving to: ‘diamonds.csv.1’\n",
      "\n",
      "diamonds.csv.1      100%[===================>]   2.64M  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-07-08 18:25:54 (158 MB/s) - ‘diamonds.csv.1’ saved [2772143/2772143]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/tidyverse/ggplot2/main/data-raw/diamonds.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6367a4b-d761-492a-adca-706a39e16b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- carat: double (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- table: double (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"diamonds.csv\", header=True, inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8adfdc3-186e-4d13-a96d-8746267927fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|      cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|    Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|  Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|     Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|  Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|     Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "| 0.24|Very Good|    J|   VVS2| 62.8| 57.0|  336|3.94|3.96|2.48|\n",
      "| 0.24|Very Good|    I|   VVS1| 62.3| 57.0|  336|3.95|3.98|2.47|\n",
      "| 0.26|Very Good|    H|    SI1| 61.9| 55.0|  337|4.07|4.11|2.53|\n",
      "| 0.22|     Fair|    E|    VS2| 65.1| 61.0|  337|3.87|3.78|2.49|\n",
      "| 0.23|Very Good|    H|    VS1| 59.4| 61.0|  338| 4.0|4.05|2.39|\n",
      "|  0.3|     Good|    J|    SI1| 64.0| 55.0|  339|4.25|4.28|2.73|\n",
      "| 0.23|    Ideal|    J|    VS1| 62.8| 56.0|  340|3.93| 3.9|2.46|\n",
      "| 0.22|  Premium|    F|    SI1| 60.4| 61.0|  342|3.88|3.84|2.33|\n",
      "| 0.31|    Ideal|    J|    SI2| 62.2| 54.0|  344|4.35|4.37|2.71|\n",
      "|  0.2|  Premium|    E|    SI2| 60.2| 62.0|  345|3.79|3.75|2.27|\n",
      "| 0.32|  Premium|    E|     I1| 60.9| 58.0|  345|4.38|4.42|2.68|\n",
      "|  0.3|    Ideal|    I|    SI2| 62.0| 54.0|  348|4.31|4.34|2.68|\n",
      "|  0.3|     Good|    J|    SI1| 63.4| 54.0|  351|4.23|4.29| 2.7|\n",
      "|  0.3|     Good|    J|    SI1| 63.8| 56.0|  351|4.23|4.26|2.71|\n",
      "|  0.3|Very Good|    J|    SI1| 62.7| 59.0|  351|4.21|4.27|2.66|\n",
      "+-----+---------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8661dd-17a8-468d-ab65-dd533c43d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34806760-699c-4de3-8396-01c0ce79644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+----------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|numeric_features|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+----------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|     [0.23,61.5]|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|     [0.21,59.8]|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|     [0.23,56.9]|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|     [0.29,62.4]|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|     [0.31,63.3]|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"carat\", \"depth\"],\n",
    "outputCol=\"numeric_features\")\n",
    "df2 = assembler.transform(df)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54eaebe3-61f7-4ab8-8c37-996bbad09211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables (stored as strings) will first have to be converted to an integer index and, when used as a feature (“covariate”), then encoded using one-hot encoding (“dummy coding”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc02e44-eb96-42bd-9e4d-69e5fa04352b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|cut_index|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|      0.0|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|      1.0|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|      3.0|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|      1.0|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|      3.0|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Convert categorical column (strings) to indexes\n",
    "indexer = StringIndexer(inputCol=\"cut\", outputCol=\"cut_index\")\n",
    "indexer_model = indexer.fit(df)\n",
    "\n",
    "df2 = indexer_model.transform(df)\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7b4d594-6527-4306-9341-41834ed08109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|cut_index|cut_index_encoded|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|      0.0|    (4,[0],[1.0])|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|      1.0|    (4,[1],[1.0])|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|      3.0|    (4,[3],[1.0])|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|      1.0|    (4,[1],[1.0])|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|      3.0|    (4,[3],[1.0])|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode indices in one hot encoding (\"dummy coding\")\n",
    "encoder = OneHotEncoder (inputCols=[\"cut_index\"],\n",
    "outputCols=[\"cut_index_encoded\"])\n",
    "\n",
    "encoder_model = encoder.fit(df2)\n",
    "\n",
    "df3 = encoder_model.transform(df2)\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d67d038-9b83-4b97-9a2d-be879e79ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86132dbf-259c-4b60-9f92-a82050fe6b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|cut_index|cut_index_encoded|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|      0.0|    (4,[0],[1.0])|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|      1.0|    (4,[1],[1.0])|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|      3.0|    (4,[3],[1.0])|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|      1.0|    (4,[1],[1.0])|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|      3.0|    (4,[3],[1.0])|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Convert categorical column (strings) to indexes\n",
    "indexer = StringIndexer (inputCol=\"cut\", outputCol=\"cut_index\")\n",
    "\n",
    "# Encode indices in one hot encoding (\"dummy coding\")\n",
    "encoder = OneHotEncoder (inputCols=[\"cut_index\"],\n",
    "outputCols=[\"cut_index_encoded\"])\n",
    "pipeline = Pipeline(stages=[indexer, encoder] )\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "\n",
    "df3 = pipeline_model.transform(df)\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2341d-6c79-428c-b98d-a0cdcb723731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the class RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "073a8f02-bcdf-4192-a021-1a2b50cca733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|            features|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|(5,[0,1],[0.23,1.0])|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|(5,[0,2],[0.21,1.0])|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|(5,[0,4],[0.23,1.0])|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|(5,[0,2],[0.29,1.0])|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|(5,[0,4],[0.31,1.0])|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "formula = RFormula(formula=\"~carat+cut\")\n",
    "formula_model = formula.fit(df)\n",
    "\n",
    "df3 = formula_model.transform(df)\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d5f6a1-0f41-4501-86eb-ec4c6c5af25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+------------------------------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|cut_index|cut_index_encoded|VectorAssembler_2de076945847__output|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+------------------------------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|      0.0|    (4,[0],[1.0])|                (5,[0,1],[0.23,1.0])|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|      1.0|    (4,[1],[1.0])|                (5,[0,2],[0.21,1.0])|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|      3.0|    (4,[3],[1.0])|                (5,[0,4],[0.23,1.0])|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|      1.0|    (4,[1],[1.0])|                (5,[0,2],[0.29,1.0])|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|      3.0|    (4,[3],[1.0])|                (5,[0,4],[0.31,1.0])|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+---------+-----------------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# same as \n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "StringIndexer(inputCol=\"cut\", outputCol=\"cut_index\"),\n",
    "OneHotEncoder(inputCols=[\"cut_index\"],\n",
    "outputCols=[\"cut_index_encoded\"]),\n",
    "VectorAssembler(inputCols=[\"carat\", \"cut_index_encoded\"])\n",
    "])\n",
    "pipeline_model = pipeline.fit(df)\n",
    "df3 = pipeline_model.transform(df)\n",
    "df3.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d73dc-634c-4448-aaf6-26c0ed26ba74",
   "metadata": {},
   "source": [
    "### Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae532560-1ab4-4fd3-8391-441f58ba6054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputCol: input column name. (undefined)\n",
      "max: Upper bound of the output feature range (default: 1.0)\n",
      "min: Lower bound of the output feature range (default: 0.0)\n",
      "outputCol: output column name. (default: MinMaxScaler_10ee5e3e0466__output)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "print(MinMaxScaler().explainParams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c41c4f10-06a1-495a-b1b5-d31651cf6e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+--------------------+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|            features|     scaled_features|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+--------------------+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|(5,[0,1],[0.23,1.0])|(5,[0,1],[0.00623...|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|(5,[0,2],[0.21,1.0])|(5,[0,2],[0.00207...|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|(5,[0,4],[0.23,1.0])|(5,[0,4],[0.00623...|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|(5,[0,2],[0.29,1.0])|(5,[0,2],[0.01871...|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|(5,[0,4],[0.31,1.0])|(5,[0,4],[0.02286...|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To illustrate the use of the above transformations we will rescale the features we have extracted from the diamonds data set to [0, 1] using MinMaxScaler\n",
    "pipeline = Pipeline(stages=[\n",
    "                    RFormula(formula=\"~carat+cut\"),\n",
    "                    MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "                    ])\n",
    "pipeline_model = pipeline.fit(df)\n",
    "\n",
    "df4 = pipeline_model.transform(df)\n",
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2142ea05-2dd4-486a-a6ed-be0ca8828005",
   "metadata": {},
   "source": [
    "### Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb053e97-be8b-4242-8c5a-a4f2c42fa38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------------+\n",
      "|label|            features|         prediction|\n",
      "+-----+--------------------+-------------------+\n",
      "|326.0|(5,[0,1],[0.23,1.0])| -264.1968244521395|\n",
      "|326.0|(5,[0,2],[0.21,1.0])|  -783.465310453415|\n",
      "|327.0|(5,[0,4],[0.23,1.0])| -944.7889563555395|\n",
      "|334.0|(5,[0,2],[0.29,1.0])|-153.77873973906617|\n",
      "|335.0|(5,[0,4],[0.31,1.0])|-315.10238564119027|\n",
      "+-----+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "pipeline = Pipeline(stages=[\n",
    "            RFormula(formula=\"price~carat+cut\"),\n",
    "            LinearRegression()\n",
    "            ])\n",
    "\n",
    "pipeline_model = pipeline.fit(df)\n",
    "\n",
    "pipeline_model.transform(df).select(\"label\", \"features\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd66153-0631-4c8a-9e83-7af5ec1fe2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print the coefficients we first need to extract the linear model, which is the last stage of the pipeline.\n",
    "regression_model = pipeline_model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91de1c97-d21d-46fc-8e49-0ed096b7d68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3875.4696997101078\n"
     ]
    }
   ],
   "source": [
    "#We can then print the intercept (which Spark stores outside the coefficients)\n",
    "print(regression_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09d5f15d-ee40-4f60-9c62-6170378b0c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7871.082133929367,1800.9239844542137,1439.0771411315254,1510.1354085136404,1120.331852550814]\n"
     ]
    }
   ],
   "source": [
    "#as well as the remaining coefficients.\n",
    "print(regression_model.coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b69348-d354-4430-8ec9-bfcab69bcfdf",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61d1b7a-430a-4820-b2d5-12e807eb5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be86a81c-5383-44ce-aff0-46b4db39dc29",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c9f01-83af-4a9a-8357-e916f9ae26b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see example 4 - end of pyinterface notebooks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
