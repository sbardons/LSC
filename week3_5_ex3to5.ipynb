{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eca9632-bdd2-4121-887a-6b9fd0f2c740",
   "metadata": {},
   "source": [
    "## Examples 3 4 5 of week 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d5acc00-66c7-4a7d-9d69-927a86903ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the libraries we'll need\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37201365-5b18-4640-aa06-7edb445c626f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 20:45:38.288062: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-28 20:45:38.845959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "y_input = tf.keras.utils.to_categorical(y_train)\n",
    "x_input = (np.reshape(x_train, (x_train.shape[0], 784)) / 255.0).astype(np.float32)\n",
    "\n",
    "# just use ten samples\n",
    "x_input = x_input[:10]\n",
    "y_input = y_input[:10]\n",
    "\n",
    "# create the variables\n",
    "W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "b = tf.Variable(tf.zeros([10]),name='b')\n",
    "\n",
    "# set-up the functions for the model\n",
    "# predicted probability for each class\n",
    "def y_pred(x):\n",
    "    # add a print statement using the standard python function\n",
    "    print(b[0])\n",
    "    return tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# cross entropy loss function\n",
    "@tf.function\n",
    "def loss(x,y):  \n",
    "    y_ = y_pred(x)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_), axis=[1]))\n",
    "\n",
    "\n",
    "# set up the optimizer\n",
    "train_steps = 5\n",
    "lr = 1e-1\n",
    "optimizer = tf.optimizers.SGD(lr)\n",
    "\n",
    "# run the training with the print statement\n",
    "for i in range(train_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(x_input,y_input)\n",
    "    gradients = tape.gradient(current_loss, [W, b])\n",
    "    train_step = optimizer.apply_gradients(zip(gradients, [W ,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b0214-370c-4a6d-922b-bdb0293b34ba",
   "metadata": {},
   "source": [
    "Although we have added the print statement, it is only being printed once when the function is first called.\n",
    "It is also only displaying the shape and datatype and not its actual value as we would like. This is because we are using graph mode, so we will have to change the code to use the tf.print\n",
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4990d57d-d9e5-48cb-8a1f-768937139b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00149583095\n",
      "-0.0019557036\n",
      "-0.0023749636\n",
      "-0.00274300273\n",
      "-0.00306231133\n"
     ]
    }
   ],
   "source": [
    "# predicted probability for each class\n",
    "def y_pred(x):\n",
    "    # use the tf.print function to print to stdout\n",
    "    tf.print(b[0], output_stream=sys.stdout)   #changed here!\n",
    "    return tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# cross entropy loss function\n",
    "@tf.function\n",
    "def loss(x,y):\n",
    "    y_ = y_pred(x)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_), axis=[1]))\n",
    "\n",
    "\n",
    "# set up the optimizer\n",
    "train_steps = 5\n",
    "lr = 1e-1\n",
    "optimizer = tf.optimizers.SGD(lr)\n",
    "\n",
    "\n",
    "# run the training with the print statement\n",
    "for i in range(train_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(x_input,y_input)\n",
    "        gradients = tape.gradient(current_loss, [W, b])\n",
    "        train_step = optimizer.apply_gradients(zip(gradients, [W ,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da51e38-eb91-45ad-b69d-2bf089e26ca0",
   "metadata": {},
   "source": [
    "## Example 4 of when learning rate is too high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4920b2ce-6bd1-43ec-aac8-79a067c9af4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00333956606\n",
      "-0.245597571\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "# learning rate\n",
    "lr = 1e2\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.optimizers.SGD(lr)\n",
    "\n",
    "# include an operation to print b\n",
    "for i in range(train_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(x_input,y_input)\n",
    "        gradients = tape.gradient(current_loss, [W, b])\n",
    "        train_step = optimizer.apply_gradients(zip(gradients, [W ,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e28bc7-1968-4d5e-8c80-96edb38f0b6b",
   "metadata": {},
   "source": [
    "## Example 5: add assert statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf795f29-e87b-40ab-969a-65d46cb4c78a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-28 21:08:19.763934: E tensorflow/core/kernels/check_numerics_op.cc:292] abnormal_detected_host @0x2030c0200 = {1, 0} stopping - weights values contain nan\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'VerifyFinite/CheckNumerics' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 22, in <module>\n      current_loss = loss(x_input,y_input)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 10, in loss\n      y_ = y_pred(x)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 3, in y_pred\n      tf.debugging.assert_all_finite(W, 'stopping - weights values contain nan')\nNode: 'VerifyFinite/CheckNumerics'\nstopping - weights values contain nan : Tensor had NaN values\n\t [[{{node VerifyFinite/CheckNumerics}}]] [Op:__forward_loss_1130]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(train_steps):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m---> 22\u001b[0m         current_loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m         gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(current_loss, [W, b])\n\u001b[1;32m     24\u001b[0m         train_step \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, [W ,b]))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'VerifyFinite/CheckNumerics' defined at (most recent call last):\n    File \"/opt/conda/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/opt/conda/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/opt/conda/lib/python3.8/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"/opt/conda/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/opt/conda/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/opt/conda/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"/opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 22, in <module>\n      current_loss = loss(x_input,y_input)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 10, in loss\n      y_ = y_pred(x)\n    File \"/tmp/ipykernel_522/1855556737.py\", line 3, in y_pred\n      tf.debugging.assert_all_finite(W, 'stopping - weights values contain nan')\nNode: 'VerifyFinite/CheckNumerics'\nstopping - weights values contain nan : Tensor had NaN values\n\t [[{{node VerifyFinite/CheckNumerics}}]] [Op:__forward_loss_1130]"
     ]
    }
   ],
   "source": [
    "# predicted probability for each class\n",
    "def y_pred(x):\n",
    "    tf.debugging.assert_all_finite(W, 'stopping - weights values contain nan')\n",
    "    tf.debugging.assert_all_finite(b, 'stopping - bias values contain nan')\n",
    "    return tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# cross entropy loss function\n",
    "@tf.function\n",
    "def loss(x,y):\n",
    "    y_ = y_pred(x)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_), axis=[1]))\n",
    "\n",
    "# learning rate\n",
    "lr = 1e2\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.optimizers.SGD(lr)\n",
    "\n",
    "#Now, when we run the code it immediately raises an error as soon as a nan occurs,\n",
    "for i in range(train_steps):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss(x_input,y_input)\n",
    "        gradients = tape.gradient(current_loss, [W, b])\n",
    "        train_step = optimizer.apply_gradients(zip(gradients, [W ,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4833316-6dd0-49e1-a5dc-70f4a97c793a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
