{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7b6279-4d7b-40fb-a466-89be456d3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sequential model   (NOT TO USE BUT KEEP)\n",
    "model = tf.keras.Sequential(name=\"model_conv1D\")\n",
    "\n",
    "model.add(tf.keras.layers.Input(shape=(128,3)))\n",
    "model.add(tf.keras.layers.Conv1D(filters=32, kernel_size=4, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())            ###check\n",
    "model.add(tf.keras.layers.Dense(6, activation='softmax'))      #how many units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459d220-e763-4aad-a6b2-6a6344677471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "\n",
    "# Callbacks\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "# create a callback that will stop training if the validation loss hasn't improved for 2 epochs\n",
    "callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)]\n",
    "# initialize tqdm callback with default parameters\n",
    "tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "loss='categorical_crossentropy',           \n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c813f-ca6a-46e0-b681-8422a1bb33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add tqdm\n",
    "# TRAIN lOW FIRST\n",
    "# train the model\n",
    "fit = model.fit(x_input, y_input, \n",
    "        epochs=500, \n",
    "        verbose=0,  #what does this mean?\n",
    "        batch_size=128,\n",
    "        callbacks=[tensorboard_callback],\n",
    "        validation_data=(x_val, y_val))\n",
    "\n",
    "# plt.plot(np.array(fit.history['loss']), \"r--\", label = \"Train loss\")\n",
    "# plt.plot(np.array(fit.history['accuracy']), \"g--\", label = \"Train accuracy\")\n",
    "# plt.plot(np.array(fit.history['val_loss']), \"r-\", label = \"Validation loss\")\n",
    "# plt.plot(np.array(fit.history['val_accuracy']), \"g-\", label = \"Validation accuracy\")\n",
    "# plt.title(\"Training session's progress over iterations\")\n",
    "# plt.legend(loc='lower left')\n",
    "# plt.ylabel('Training Progress (Loss/Accuracy)')\n",
    "# plt.xlabel('Training Epoch')\n",
    "# plt.ylim(0) \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15639f64-8038-49fb-9a66-62f09b435581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f264254-b445-4d69-9a94-47b7a4a2234e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585a00e-580c-44cb-9891-d871d568a451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61699dcd-5325-4132-b5ed-dc10dae4e96b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8436ca3-78bb-43ba-827a-7c5545a0e3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
