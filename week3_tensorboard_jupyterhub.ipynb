{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8352ec0-07c4-491f-baaa-6045349bb6c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Example of how to use tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a49ef68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "y_input = tf.keras.utils.to_categorical(y_train)\n",
    "x_input = (np.reshape(x_train, (x_train.shape[0], 784)) / 255.0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1ee6112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784,10]),name='W')\n",
    "b = tf.Variable(tf.zeros([10]),name='b')\n",
    "\n",
    "# predicted probability for each class\n",
    "def y_pred(x):\n",
    "    return tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# cross entropy loss function\n",
    "@tf.function\n",
    "def loss(x,y):\n",
    "    y_ = y_pred(x)\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y * tf.math.log(y_), axis=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d025a-bf24-4afe-8d2a-39e9cd645e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard                   in Colab only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3596cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up logging jupiterhub\n",
    "logdir = '/home/jovyan/logs'\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "\n",
    "# Bracket the function call with trace_on and trace_export\n",
    "tf.summary.trace_on()\n",
    "# Call only one tf.function when tracing.\n",
    "z = loss(x_input, y_input)     #this compiles the graph\n",
    "with writer.as_default():\n",
    "    tf.summary.trace_export(name='graph',step=0) #iteration of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfdc105-6da4-41e4-a7f2-53b53d422d98",
   "metadata": {},
   "source": [
    "## Now let's see how the loss is changing over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a77a141c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now add in the training bits of the graph\n",
    "train_steps = 500\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.optimizers.SGD(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f5676f5-89b2-44ed-9e91-d94d679cfbce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with writer.as_default(): # use the contex manager to specify the writer\n",
    "    for i in range(train_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            current_loss = loss(x_input,y_input)\n",
    "        gradients = tape.gradient(current_loss, [W, b])\n",
    "        optimizer.apply_gradients(zip(gradients, [W ,b]))\n",
    "        # write the value to tensorboard summary stats\n",
    "        if i%20 ==0: #every 20 time steps\n",
    "            tf.summary.scalar('loss', current_loss, step=i)  #single number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1e8a61-f27b-4395-acad-fd88a0e2cc8c",
   "metadata": {},
   "source": [
    "## Output slice of the weights value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90095c-e792-4f1a-ac9d-710c4e81b229",
   "metadata": {},
   "source": [
    "### Rerun cell 1 and 2 first to reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "962fa379-8224-4270-b443-fac7d1bcb06b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now add in the training bits of the graph\n",
    "train_steps = 500\n",
    "\n",
    "# learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# gradient descent optimizer\n",
    "optimizer = tf.optimizers.SGD(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73980d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with writer.as_default(): # use the contex manager to specify the writer\n",
    "    for i in range(train_steps):\n",
    "        with tf.GradientTape() as tape:\n",
    "            current_loss = loss(x_input,y_input)\n",
    "        gradients = tape.gradient(current_loss, [W, b])\n",
    "        optimizer.apply_gradients(zip(gradients, [W ,b]))\n",
    "        # write the value to tensorboard summary stats\n",
    "        if i%20 ==0: \n",
    "            W_slice = tf.reshape(W[:,0],[1,28,28,1])    # extra 1 are paddings\n",
    "            tf.summary.image('image', W_slice, step=i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eebdbc5-d601-498e-a842-ebaf12f308fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62903a5-26f2-4f67-b6da-290d321d25c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
